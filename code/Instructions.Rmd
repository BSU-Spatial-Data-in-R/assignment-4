---
title: "Common raster operations using terra"
author: "Matt Williamson"
date: "9/16/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Your assignment

The goals for this assignment are to:

- practice raster operations using the `terra` package

- begin using functional programming for repetitive operations

By the time you work through these steps you should have a `SpatRaster` object with elevation, climate, and land value data that is cropped to Idaho.


## Step 1: Load your packages
We will rely on the `terra` and `geodata` packages for this assignment. Load them here
```{r packageload}

```


## Step 2: Use `geodata` to download some data

Our spatial analyses are often built upon a mix of data that we (or our colleagues) generated ourselves and data that is freely available through a variety of platforms and portals (see the Resources section of the course page if you're interested in a few other data options). In some cases, very nice people have generated `R` packages to facilitate data access _within_ the `R` script to aid in reproducibility. We'll be using the `geodata` package today, but there are a number of others (the [`FedData` ](https://github.com/ropensci/FedData) package is another handy one). Use the `elevation_30s()` and the `cmip6_world()` functions to download a raster of eleveation for the United States and the projected maximum temperature across the globe (you'll need to use the `?` to access the helpfiles to understand how these functions work). Make sure to assign the result of each to an object (i.e., one object in your workspace should contain the elevation data and one should contain the climate data). Inspect these objects.

```{r dldata}

```

* __Question 1:__ What class is each object returned by the functions? What are their origins, extents, and resolutions? What CRS are they using?
* __Question 2:__ Look at the helpfile for `rast()`. How might you determine the number of layers in the elevation and climate objects you created? 
* __Question 3:__ How many layers are in each object?


## Step 3: Load your own data
Now that you know a bit more about the `rast()` function you should be able to use it to load some raster data from a file (rather than download it within a package). You'll find the land value raster from session 4 in our shared folder (`/opt/data/session08/`). Load that here.

```{r loaddata}

```


## Step 4: Line up our rasters.
As we have discussed, before we can do much in terms of spatial analysis, we need to get all of our pieces to line up. This involves checking to make sure each raster has the same CRS, extent, origin, and resolution (note that having the same resolution is mostly a convenience for combining layers in a single object, changing resolution has a lot of consequences for our analyses so do it with some thought). We'll use `project()` and `crop()` to get the data cut down to size and then a combination of `aggregate()`, `disaggregate()`, and `resample()` to get the resolutions and origins aligned.

```{r alignrast}

```

* Question 3: What attributes (variables) does the shapefile contain? Are the geometries valid? What kind of object is it?

* Question 4: How large (in km) are the parcels in the dataset?

## Step 5: Let's smooth these parcels a bit
Parcel boundaries are often drawn at extremely fine resolutions. This means that there are a lot of vertices for relatively small polygons. Let's smooth some of that detail out using `st_simplify`. Do that here.
```{r simplepolys}

```
* Question 5: What arguments does `st_simplify` accept?

* Question 6: How does changing the tolerance affect the look and area of the resulting polygons? Does the geometry remain valid?

## Step 6: Let's get the centroids of the parcels in the original shapefile
Estimating distances to polygons can be ambiguous because of their irregular shapes and different edge-area ratios. One way to 'standardize' the calculation is to measure distances to the geographic centroid. In order to do that we have to find the centroids of the existing parcel polygons (not the ones you simplified). Do that here.
```{r polycents}

```

## Step 7: How far is each parcel from the University of Idaho?
Use the `dplyr::filter` command to select the University of Idaho from your university shapefile, then estimate the distance between the U of I and all of the ID parcel centroids you just estimated.
```{r centdist}

```
* Question 7: How far away is the farthest parcel in the dataset? Who was the original owner of that parcel?

## Bonus: Make a map illustrating the extent of the parcel dataset compared to the university dataset
Create a polygon that is 10m smaller than the extent of the parcel dataset, then plot the university dataset with your new polygon overlaid. (Hint: you can use `st_bbox` to get the coordinates of the bounding box)
